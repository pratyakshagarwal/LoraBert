{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.parametrize as parametrize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "from src.train_func import train, test\n",
    "from src.loRA import LoRAParametrization, lora_parameterization, enable_disable_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "torch.set_printoptions(precision=3, linewidth=125, sci_mode=False)\n",
    "_=torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANK = 4\n",
    "MODEL_NAME = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "DATA_PATH = \"../data/finnews.csv\"\n",
    "TRND_BERT_PTH = \"../models/whtout-lora-trainedbert.pth\"\n",
    "TRND_BERTLORA_PTH =  \"../models/wht-lora-trainedbert.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "finbert = AutoModel.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "total_parameter_original = sum([p.numel() for p in finbert.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14350248"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_parameter_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_PATH)\n",
    "encoders = {'neutral':0, 'positive':1, 'negative':2}\n",
    "label_encoders = {k:i for i,k in encoders.items()}\n",
    "data['sentiment'] = data['sentiment'].map(encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FinBERTSentimentClassifier(torch.nn.Module):\n",
    "    def __init__(self, finbert):\n",
    "        super(FinBERTSentimentClassifier, self).__init__()\n",
    "        self.finbert = finbert\n",
    "        self.classifier = torch.nn.Linear(self.finbert.config.hidden_size, 3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get the pooled output from FinBERT\n",
    "        outputs = self.finbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooler_output = outputs.pooler_output  # Shape: (batch_size, hidden_size)\n",
    "        logits = self.classifier(pooler_output)\n",
    "        return logits\n",
    "\n",
    "model = FinBERTSentimentClassifier(finbert)\n",
    "model.load_state_dict(torch.load(TRND_BERT_PTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finbert.embeddings.word_embeddings.weight: torch.Size([30522, 312])\n",
      "finbert.embeddings.position_embeddings.weight: torch.Size([512, 312])\n",
      "finbert.embeddings.token_type_embeddings.weight: torch.Size([2, 312])\n",
      "finbert.encoder.layer.0.attention.self.query.weight: torch.Size([312, 312])\n",
      "finbert.encoder.layer.0.attention.self.query.bias: torch.Size([312])\n",
      "finbert.encoder.layer.0.attention.self.key.weight: torch.Size([312, 312])\n",
      "finbert.encoder.layer.0.attention.self.key.bias: torch.Size([312])\n",
      "finbert.encoder.layer.0.attention.self.value.weight: torch.Size([312, 312])\n",
      "finbert.encoder.layer.0.attention.self.value.bias: torch.Size([312])\n",
      "finbert.encoder.layer.0.attention.output.dense.weight: torch.Size([312, 312])\n",
      "finbert.encoder.layer.0.attention.output.dense.bias: torch.Size([312])\n",
      "finbert.encoder.layer.0.intermediate.dense.weight: torch.Size([1200, 312])\n",
      "finbert.encoder.layer.0.intermediate.dense.bias: torch.Size([1200])\n",
      "finbert.encoder.layer.0.output.dense.weight: torch.Size([312, 1200])\n",
      "finbert.encoder.layer.0.output.dense.bias: torch.Size([312])\n",
      "finbert.encoder.layer.1.attention.self.query.weight: torch.Size([312, 312])\n",
      "finbert.encoder.layer.1.attention.self.query.bias: torch.Size([312])\n",
      "finbert.encoder.layer.1.attention.self.key.weight: torch.Size([312, 312])\n",
      "finbert.encoder.layer.1.attention.self.key.bias: torch.Size([312])\n",
      "finbert.encoder.layer.1.attention.self.value.weight: torch.Size([312, 312])\n",
      "finbert.encoder.layer.1.attention.self.value.bias: torch.Size([312])\n",
      "finbert.encoder.layer.1.attention.output.dense.weight: torch.Size([312, 312])\n",
      "finbert.encoder.layer.1.attention.output.dense.bias: torch.Size([312])\n",
      "finbert.encoder.layer.1.intermediate.dense.weight: torch.Size([1200, 312])\n",
      "finbert.encoder.layer.1.intermediate.dense.bias: torch.Size([1200])\n",
      "finbert.encoder.layer.1.output.dense.weight: torch.Size([312, 1200])\n",
      "finbert.encoder.layer.1.output.dense.bias: torch.Size([312])\n",
      "finbert.encoder.layer.2.attention.self.query.weight: torch.Size([312, 312])\n",
      "finbert.encoder.layer.2.attention.self.query.bias: torch.Size([312])\n",
      "finbert.encoder.layer.2.attention.self.key.weight: torch.Size([312, 312])\n",
      "finbert.encoder.layer.2.attention.self.key.bias: torch.Size([312])\n",
      "finbert.encoder.layer.2.attention.self.value.weight: torch.Size([312, 312])\n",
      "finbert.encoder.layer.2.attention.self.value.bias: torch.Size([312])\n",
      "finbert.encoder.layer.2.attention.output.dense.weight: torch.Size([312, 312])\n",
      "finbert.encoder.layer.2.attention.output.dense.bias: torch.Size([312])\n",
      "finbert.encoder.layer.2.intermediate.dense.weight: torch.Size([1200, 312])\n",
      "finbert.encoder.layer.2.intermediate.dense.bias: torch.Size([1200])\n",
      "finbert.encoder.layer.2.output.dense.weight: torch.Size([312, 1200])\n",
      "finbert.encoder.layer.2.output.dense.bias: torch.Size([312])\n",
      "finbert.encoder.layer.3.attention.self.query.weight: torch.Size([312, 312])\n",
      "finbert.encoder.layer.3.attention.self.query.bias: torch.Size([312])\n",
      "finbert.encoder.layer.3.attention.self.key.weight: torch.Size([312, 312])\n",
      "finbert.encoder.layer.3.attention.self.key.bias: torch.Size([312])\n",
      "finbert.encoder.layer.3.attention.self.value.weight: torch.Size([312, 312])\n",
      "finbert.encoder.layer.3.attention.self.value.bias: torch.Size([312])\n",
      "finbert.encoder.layer.3.attention.output.dense.weight: torch.Size([312, 312])\n",
      "finbert.encoder.layer.3.attention.output.dense.bias: torch.Size([312])\n",
      "finbert.encoder.layer.3.intermediate.dense.weight: torch.Size([1200, 312])\n",
      "finbert.encoder.layer.3.intermediate.dense.bias: torch.Size([1200])\n",
      "finbert.encoder.layer.3.output.dense.weight: torch.Size([312, 1200])\n",
      "finbert.encoder.layer.3.output.dense.bias: torch.Size([312])\n",
      "finbert.pooler.dense.weight: torch.Size([312, 312])\n",
      "finbert.pooler.dense.bias: torch.Size([312])\n",
      "classifier.weight: torch.Size([3, 312])\n",
      "classifier.bias: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for name, params in model.named_parameters():\n",
    "    module = dict(model.named_modules()).get(name.rsplit('.', 1)[0])\n",
    "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "        print(f\"{name}: {params.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def apply_lora(model, layers, rank=1):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, layers):\n",
    "            parametrize.register_parametrization(\n",
    "                module, \"weight\", lora_parameterization(module, device, rank=rank)\n",
    "            )\n",
    "\n",
    "apply_lora(model=model, layers=(nn.Linear, nn.Embedding), rank=RANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: torch.Size([30522, 312])  Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([30522, 4])\n",
      "W: torch.Size([512, 312])  Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([512, 4])\n",
      "W: torch.Size([2, 312])  Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([2, 4])\n",
      "W: torch.Size([312, 312]) + B: torch.Size([312]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([312, 312]) + B: torch.Size([312]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([312, 312]) + B: torch.Size([312]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([312, 312]) + B: torch.Size([312]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([1200, 312]) + B: torch.Size([1200]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([1200, 4])\n",
      "W: torch.Size([312, 1200]) + B: torch.Size([312]) Lora_A: torch.Size([4, 1200]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([312, 312]) + B: torch.Size([312]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([312, 312]) + B: torch.Size([312]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([312, 312]) + B: torch.Size([312]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([312, 312]) + B: torch.Size([312]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([1200, 312]) + B: torch.Size([1200]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([1200, 4])\n",
      "W: torch.Size([312, 1200]) + B: torch.Size([312]) Lora_A: torch.Size([4, 1200]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([312, 312]) + B: torch.Size([312]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([312, 312]) + B: torch.Size([312]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([312, 312]) + B: torch.Size([312]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([312, 312]) + B: torch.Size([312]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([1200, 312]) + B: torch.Size([1200]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([1200, 4])\n",
      "W: torch.Size([312, 1200]) + B: torch.Size([312]) Lora_A: torch.Size([4, 1200]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([312, 312]) + B: torch.Size([312]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([312, 312]) + B: torch.Size([312]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([312, 312]) + B: torch.Size([312]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([312, 312]) + B: torch.Size([312]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([1200, 312]) + B: torch.Size([1200]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([1200, 4])\n",
      "W: torch.Size([312, 1200]) + B: torch.Size([312]) Lora_A: torch.Size([4, 1200]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([312, 312]) + B: torch.Size([312]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([312, 4])\n",
      "W: torch.Size([3, 312]) + B: torch.Size([3]) Lora_A: torch.Size([4, 312]) + Lora_B: torch.Size([3, 4])\n",
      "Total number of parameters (original): 14,345,571\n",
      "Total number of parameters (original + LoRA): 14,565,535\n",
      "Parameters introduced by LoRA: 219,964\n",
      "Parameters incremment: 1.533%\n"
     ]
    }
   ],
   "source": [
    "total_parameters_lora = 0\n",
    "total_parameters_non_lora = 0\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        total_parameters_lora += layer.parametrizations[\"weight\"][0].lora_A.nelement() + layer.parametrizations[\"weight\"][0].lora_B.nelement()\n",
    "        total_parameters_non_lora += layer.weight.nelement() + layer.bias.nelement()\n",
    "        print(\n",
    "            f'W: {layer.weight.shape} + B: {layer.bias.shape} Lora_A: {layer.parametrizations[\"weight\"][0].lora_A.shape} + Lora_B: {layer.parametrizations[\"weight\"][0].lora_B.shape}'\n",
    "        )\n",
    "    if isinstance(layer, nn.Embedding):\n",
    "        total_parameters_lora += layer.parametrizations[\"weight\"][0].lora_A.nelement() + layer.parametrizations[\"weight\"][0].lora_B.nelement()\n",
    "        total_parameters_non_lora += layer.weight.nelement()\n",
    "        print(\n",
    "            f'W: {layer.weight.shape}  Lora_A: {layer.parametrizations[\"weight\"][0].lora_A.shape} + Lora_B: {layer.parametrizations[\"weight\"][0].lora_B.shape}'\n",
    "        )\n",
    "    # else:\n",
    "    #     total_parameters_non_lora += layer.weight.nelement()\n",
    "\n",
    "# assert total_parameters_non_lora == total_parameter_original\n",
    "print(f'Total number of parameters (original): {total_parameters_non_lora:,}')\n",
    "print(f'Total number of parameters (original + LoRA): {total_parameters_lora + total_parameters_non_lora:,}')\n",
    "print(f'Parameters introduced by LoRA: {total_parameters_lora:,}')\n",
    "parameters_incremment = (total_parameters_lora / total_parameters_non_lora) * 100\n",
    "print(f'Parameters incremment: {parameters_incremment:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_params(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        # Check if 'lora' is not in the parameter name and it is not the classifier layer\n",
    "        if 'lora' not in name and 'classifier' not in name and 'fc' not in name:  # Add any keywords identifying the classifier\n",
    "            print(f'Freezing non-LoRA parameter {name}')\n",
    "            param.requires_grad = False\n",
    "\n",
    "freeze_params(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen Parameters: 14350248\n",
      "Trainable Parameters: 220903\n"
     ]
    }
   ],
   "source": [
    "def check_frozen_parameters(model):\n",
    "    frozen_params = []\n",
    "    trainable_params = []\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            trainable_params.append(param)\n",
    "        else:\n",
    "            frozen_params.append(param)\n",
    "\n",
    "    print(f\"Frozen Parameters: {sum([p.nelement() for p in frozen_params])}\")\n",
    "    print(f\"Trainable Parameters: {sum([p.nelement() for p in trainable_params])}\")\n",
    "    \n",
    "check_frozen_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinData(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y, tokenizer, device='cpu'):self.x,self.y,self.tokenizer,self.device = x,y,tokenizer,device\n",
    "    def __len__(self):return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.tokenizer(self.x[idx], return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=256)\n",
    "        input_ids = inputs[\"input_ids\"].squeeze().to(self.device)\n",
    "        attention_mask = inputs[\"attention_mask\"].squeeze().to(self.device)\n",
    "        label = torch.tensor(self.y[idx], dtype=torch.long).to(self.device)\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GET_DLS:\n",
    "    def __init__(self, data, tsz, random_state):self.data, self.tsz, self.random_state = data, tsz, random_state\n",
    "    def get_dls(self, batch_size):\n",
    "        # split training and testing data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.data['news'], self.data['sentiment'], test_size=self.tsz, random_state=self.random_state)\n",
    "        X_train, X_test, y_train, y_test = [df.reset_index(drop=True) for df in (X_train, X_test, y_train, y_test)]\n",
    "        \n",
    "        # make train dataset and dataloader\n",
    "        train_dataset = FinData(X_train, y_train, tokenizer)\n",
    "        train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # make test dataset and dataloader\n",
    "        test_dataset = FinData(X_test, y_test, tokenizer)\n",
    "        test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size*2, shuffle=True)\n",
    "        \n",
    "        return train_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(TRND_BERTLORA_PTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSZ = 0.33\n",
    "RANDOM_STATE = 42\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 1\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, test_dl = GET_DLS(data, tsz=TSZ, random_state=RANDOM_STATE).get_dls(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1238/1238 [27:24<00:00,  1.33s/it, loss=0.0657]\n",
      "Testing: 100%|██████████| 305/305 [05:08<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss: 0.066, val loss: 0.256, train acc: 0.980, val acc: 0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    train_loader=train_dl,\n",
    "    test_dl=test_dl,\n",
    "    net=model,\n",
    "    epochs=EPOCHS,\n",
    "    total_iterations_limit=None,\n",
    "    device=\"cpu\",\n",
    "    lr=LR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../models/wht-lora-trainedbert.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def get_predictions(model, dl, device):\n",
    "    model.eval()\n",
    "    predictions,targets = [],[]\n",
    "    with torch.no_grad():\n",
    "        for data, labels in tqdm(dl, desc=\"Predicting\"):\n",
    "            input_ids = data['input_ids'].to(device)\n",
    "            attn_masks = data['attention_mask'].to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(input_ids, attn_masks)\n",
    "            outputs = F.softmax(logits, dim=-1)\n",
    "            pred = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "            predictions.extend(labels.cpu().detach())\n",
    "            targets.extend(pred.cpu().detach())\n",
    "    return predictions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predictiong: 100%|██████████| 305/305 [06:35<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions, targets = get_predictions(model, test_dl, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_cmf(preds, targs, nmc, save:str=None):\n",
    "    mcm = MulticlassConfusionMatrix(num_classes=3)\n",
    "    preds = torch.tensor(preds)\n",
    "    targs = torch.tensor(targs)\n",
    "    cmf = mcm(preds, targs)\n",
    "    sns.heatmap(cmf, annot=True, fmt='g', cmap='coolwarm', linewidths=0.5)\n",
    "    if save is not None:plt.savefig(save)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_cmf(predictions, targets, nmc=3, save=\"../figures/confusion-mtx.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiments(model, dl, n, label_encoders):\n",
    "    texts, real_sentiments, predicted_sentiments = [], [], []\n",
    "\n",
    "    for data, labels in dl:\n",
    "        random_indices = torch.randint(0, data['input_ids'].size(0), (n,))\n",
    "        random_input_ids = data['input_ids'][random_indices]\n",
    "        random_attention_mask = data['attention_mask'][random_indices]\n",
    "        random_labels = labels[random_indices]\n",
    "\n",
    "        logits = model(random_input_ids, random_attention_mask)\n",
    "        preds = torch.argmax(F.softmax(logits, dim=-1), dim=-1)\n",
    "\n",
    "        texts = [tokenizer.decode(ids.cpu(), skip_special_tokens=True) for ids in random_input_ids]\n",
    "        real_sentiments = [label_encoders[label.item()] for label in random_labels]\n",
    "        predicted_sentiments = [label_encoders[pred.item()] for pred in preds]\n",
    "        break  \n",
    "\n",
    "    for i, (text, real, pred) in enumerate(zip(texts, real_sentiments, predicted_sentiments), 1):\n",
    "        print(f\"Text {i}: {text}\")\n",
    "        print(f\"  Real Sentiment: {real}\")\n",
    "        print(f\"  Predicted Sentiment: {pred}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    return texts, real_sentiments, predicted_sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: the purchase price was not disclosed.\n",
      "  Real Sentiment: neutral\n",
      "  Predicted Sentiment: neutral\n",
      "--------------------------------------------------\n",
      "Text 2: these moderate but significant changes resulted in a significant 24 - 32 % reduction in the estimated cvd risk.\n",
      "  Real Sentiment: positive\n",
      "  Predicted Sentiment: positive\n",
      "--------------------------------------------------\n",
      "Text 3: operating profit rose to eur2. 4 m from eur1. 6 m year earlier.\n",
      "  Real Sentiment: positive\n",
      "  Predicted Sentiment: positive\n",
      "--------------------------------------------------\n",
      "Text 4: pre - tax loss totaled eur 0. 3 mn, compared to a loss of eur 2. 2 mn in the first quarter of 2005.\n",
      "  Real Sentiment: positive\n",
      "  Predicted Sentiment: positive\n",
      "--------------------------------------------------\n",
      "Text 5: we aim to ensure that vacon is in good shape when capital expenditure starts to pick up again,'' comments vacon plc president and ceo vesa laisi.\n",
      "  Real Sentiment: positive\n",
      "  Predicted Sentiment: positive\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['the purchase price was not disclosed.',\n",
       "  'these moderate but significant changes resulted in a significant 24 - 32 % reduction in the estimated cvd risk.',\n",
       "  'operating profit rose to eur2. 4 m from eur1. 6 m year earlier.',\n",
       "  'pre - tax loss totaled eur 0. 3 mn, compared to a loss of eur 2. 2 mn in the first quarter of 2005.',\n",
       "  \"we aim to ensure that vacon is in good shape when capital expenditure starts to pick up again,'' comments vacon plc president and ceo vesa laisi.\"],\n",
       " ['neutral', 'positive', 'positive', 'positive', 'positive'],\n",
       " ['neutral', 'positive', 'positive', 'positive', 'positive'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiments(model, test_dl, n=5, label_encoders=label_encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
